{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing numy, pandas, count Vectorizer,GridSearchCV,\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting traning and testing datasets in pandas \n",
    "training_data = pd.read_csv(\"twitter_train_data.csv\",delimiter=',')\n",
    "testing_data = pd.read_csv(\"twitter_test_data.csv\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.098000e+04</td>\n",
       "      <td>10980</td>\n",
       "      <td>10980</td>\n",
       "      <td>31</td>\n",
       "      <td>10980</td>\n",
       "      <td>24</td>\n",
       "      <td>10980.000000</td>\n",
       "      <td>10980</td>\n",
       "      <td>776</td>\n",
       "      <td>10980</td>\n",
       "      <td>7430</td>\n",
       "      <td>7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6438</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10851</td>\n",
       "      <td>632</td>\n",
       "      <td>10758</td>\n",
       "      <td>2658</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>negative</td>\n",
       "      <td>JetBlueNews</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@united thanks</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>2015-02-24 11:38:11 -0800</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6851</td>\n",
       "      <td>2928</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>2819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692169e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.795438e+14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675883e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685584e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694753e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698902e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703106e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweet_id airline_sentiment airline airline_sentiment_gold  \\\n",
       "count   1.098000e+04             10980   10980                     31   \n",
       "unique           NaN                 3       6                      3   \n",
       "top              NaN          negative  United               negative   \n",
       "freq             NaN              6851    2928                     24   \n",
       "mean    5.692169e+17               NaN     NaN                    NaN   \n",
       "std     7.795438e+14               NaN     NaN                    NaN   \n",
       "min     5.675883e+17               NaN     NaN                    NaN   \n",
       "25%     5.685584e+17               NaN     NaN                    NaN   \n",
       "50%     5.694753e+17               NaN     NaN                    NaN   \n",
       "75%     5.698902e+17               NaN     NaN                    NaN   \n",
       "max     5.703106e+17               NaN     NaN                    NaN   \n",
       "\n",
       "               name     negativereason_gold  retweet_count            text  \\\n",
       "count         10980                      24   10980.000000           10980   \n",
       "unique         6438                      11            NaN           10851   \n",
       "top     JetBlueNews  Customer Service Issue            NaN  @united thanks   \n",
       "freq             43                       9            NaN               6   \n",
       "mean            NaN                     NaN       0.080965             NaN   \n",
       "std             NaN                     NaN       0.740303             NaN   \n",
       "min             NaN                     NaN       0.000000             NaN   \n",
       "25%             NaN                     NaN       0.000000             NaN   \n",
       "50%             NaN                     NaN       0.000000             NaN   \n",
       "75%             NaN                     NaN       0.000000             NaN   \n",
       "max             NaN                     NaN      44.000000             NaN   \n",
       "\n",
       "       tweet_coord              tweet_created tweet_location  \\\n",
       "count          776                      10980           7430   \n",
       "unique         632                      10758           2658   \n",
       "top     [0.0, 0.0]  2015-02-24 11:38:11 -0800   New York, NY   \n",
       "freq           131                          3            125   \n",
       "mean           NaN                        NaN            NaN   \n",
       "std            NaN                        NaN            NaN   \n",
       "min            NaN                        NaN            NaN   \n",
       "25%            NaN                        NaN            NaN   \n",
       "50%            NaN                        NaN            NaN   \n",
       "75%            NaN                        NaN            NaN   \n",
       "max            NaN                        NaN            NaN   \n",
       "\n",
       "                     user_timezone  \n",
       "count                         7403  \n",
       "unique                          78  \n",
       "top     Eastern Time (US & Canada)  \n",
       "freq                          2819  \n",
       "mean                           NaN  \n",
       "std                            NaN  \n",
       "min                            NaN  \n",
       "25%                            NaN  \n",
       "50%                            NaN  \n",
       "75%                            NaN  \n",
       "max                            NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing training data by using describe function\n",
    "training_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.660000e+03</td>\n",
       "      <td>3660</td>\n",
       "      <td>9</td>\n",
       "      <td>3660</td>\n",
       "      <td>8</td>\n",
       "      <td>3660.000000</td>\n",
       "      <td>3660</td>\n",
       "      <td>243</td>\n",
       "      <td>3660</td>\n",
       "      <td>2477</td>\n",
       "      <td>2417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2805</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3650</td>\n",
       "      <td>209</td>\n",
       "      <td>3635</td>\n",
       "      <td>1258</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>United</td>\n",
       "      <td>negative</td>\n",
       "      <td>JetBlueNews</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@AmericanAir Aww cool! It's nice to know they ...</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>2015-02-24 09:54:34 -0800</td>\n",
       "      <td>USA</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>894</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692226e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.779030e+14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675924e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685633e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694842e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698927e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703083e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweet_id airline airline_sentiment_gold         name  \\\n",
       "count   3.660000e+03    3660                      9         3660   \n",
       "unique           NaN       6                      2         2805   \n",
       "top              NaN  United               negative  JetBlueNews   \n",
       "freq             NaN     894                      8           20   \n",
       "mean    5.692226e+17     NaN                    NaN          NaN   \n",
       "std     7.779030e+14     NaN                    NaN          NaN   \n",
       "min     5.675924e+17     NaN                    NaN          NaN   \n",
       "25%     5.685633e+17     NaN                    NaN          NaN   \n",
       "50%     5.694842e+17     NaN                    NaN          NaN   \n",
       "75%     5.698927e+17     NaN                    NaN          NaN   \n",
       "max     5.703083e+17     NaN                    NaN          NaN   \n",
       "\n",
       "           negativereason_gold  retweet_count  \\\n",
       "count                        8    3660.000000   \n",
       "unique                       6            NaN   \n",
       "top     Customer Service Issue            NaN   \n",
       "freq                         3            NaN   \n",
       "mean                       NaN       0.087705   \n",
       "std                        NaN       0.762048   \n",
       "min                        NaN       0.000000   \n",
       "25%                        NaN       0.000000   \n",
       "50%                        NaN       0.000000   \n",
       "75%                        NaN       0.000000   \n",
       "max                        NaN      32.000000   \n",
       "\n",
       "                                                     text tweet_coord  \\\n",
       "count                                                3660         243   \n",
       "unique                                               3650         209   \n",
       "top     @AmericanAir Aww cool! It's nice to know they ...  [0.0, 0.0]   \n",
       "freq                                                    2          33   \n",
       "mean                                                  NaN         NaN   \n",
       "std                                                   NaN         NaN   \n",
       "min                                                   NaN         NaN   \n",
       "25%                                                   NaN         NaN   \n",
       "50%                                                   NaN         NaN   \n",
       "75%                                                   NaN         NaN   \n",
       "max                                                   NaN         NaN   \n",
       "\n",
       "                    tweet_created tweet_location               user_timezone  \n",
       "count                        3660           2477                        2417  \n",
       "unique                       3635           1258                          59  \n",
       "top     2015-02-24 09:54:34 -0800            USA  Eastern Time (US & Canada)  \n",
       "freq                            3             43                         925  \n",
       "mean                          NaN            NaN                         NaN  \n",
       "std                           NaN            NaN                         NaN  \n",
       "min                           NaN            NaN                         NaN  \n",
       "25%                           NaN            NaN                         NaN  \n",
       "50%                           NaN            NaN                         NaN  \n",
       "75%                           NaN            NaN                         NaN  \n",
       "max                           NaN            NaN                         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing testing data by using describe function\n",
    "testing_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=training_data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        negative\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        negative\n",
       "5        negative\n",
       "6        negative\n",
       "7        positive\n",
       "8        negative\n",
       "9        positive\n",
       "10       negative\n",
       "11        neutral\n",
       "12       positive\n",
       "13       negative\n",
       "14       negative\n",
       "15       negative\n",
       "16       negative\n",
       "17       negative\n",
       "18       negative\n",
       "19       negative\n",
       "20       negative\n",
       "21        neutral\n",
       "22       negative\n",
       "23       negative\n",
       "24       positive\n",
       "25        neutral\n",
       "26       negative\n",
       "27       negative\n",
       "28       positive\n",
       "29       positive\n",
       "           ...   \n",
       "10950    positive\n",
       "10951    negative\n",
       "10952    negative\n",
       "10953    negative\n",
       "10954    negative\n",
       "10955    negative\n",
       "10956     neutral\n",
       "10957    negative\n",
       "10958    negative\n",
       "10959    negative\n",
       "10960    negative\n",
       "10961    negative\n",
       "10962     neutral\n",
       "10963    negative\n",
       "10964    negative\n",
       "10965     neutral\n",
       "10966    negative\n",
       "10967    negative\n",
       "10968    negative\n",
       "10969    positive\n",
       "10970    negative\n",
       "10971     neutral\n",
       "10972    negative\n",
       "10973    negative\n",
       "10974    positive\n",
       "10975     neutral\n",
       "10976    positive\n",
       "10977    negative\n",
       "10978    negative\n",
       "10979    negative\n",
       "Name: airline_sentiment, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@SouthwestAir I am scheduled for the morning, 2 days after the fact, yes..not sure why my evening flight was the only one Cancelled Flightled'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING THE TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting stopwords in stop as a set\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "punctn = set(string.punctuation)\n",
    "stop.update(punctn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing lemmatizer and pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get simple part of speech used by wordnet\n",
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    if(tag.startswith('J')):\n",
    "        return wordnet.ADJ\n",
    "    elif(tag.startswith('V')):\n",
    "        return wordnet.VERB\n",
    "    elif(tag.startswith('N')):\n",
    "        return wordnet.NOUN\n",
    "    elif(tag.startswith('R')):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "twitter_texts=[]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for texts in xtrain:\n",
    "    words = word_tokenize(texts)\n",
    "    lemmatized_texts = \"\"\n",
    "    for word in words:\n",
    "        pos = pos_tag([word])\n",
    "        lemmatized_texts = lemmatized_texts + \" \" +lemmatizer.lemmatize(word,get_simple_pos(pos[0][1]))\n",
    "    twitter_texts.append(lemmatized_texts)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10980x500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 80042 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making an objet of count Vectorizer,passing the argument max_feature, ngram_range, stop_words, max_df,min_df,then fit transform \n",
    "#training data\n",
    "count_vec = CountVectorizer(max_features=500,ngram_range=(1,3),stop_words=stop,max_df=0.90,min_df=0.001)\n",
    "xtrain = count_vec.fit_transform(twitter_texts)\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10980x391 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 74909 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer(max_features=500,ngram_range=(1,3),stop_words=stop,max_df=0.90,min_df=0.005)\n",
    "xtrain2 = tfidf_vec.fit_transform(twitter_texts)\n",
    "xtrain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3660x500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 22543 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting test data in String of array because count vectorizer takes only in these formats after tranform it will give a sparse matrix \n",
    "twitter_texts_test=[]\n",
    "for text in testing_data[\"text\"]:\n",
    "    twitter_texts_test.append(text)\n",
    "xtest = count_vec.transform(twitter_texts_test)\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3660x391 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21107 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using TF IDF Vectorizer transforming test data\n",
    "twitter_texts_test_tf=[]\n",
    "for text in testing_data[\"text\"]:\n",
    "    twitter_texts_test_tf.append(text)\n",
    "xtest2 = tfidf_vec.transform(twitter_texts_test_tf)\n",
    "xtest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '11',\n",
       " '12',\n",
       " '15',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '24',\n",
       " '25',\n",
       " '30',\n",
       " '40',\n",
       " '45',\n",
       " '50',\n",
       " '800',\n",
       " 'aa',\n",
       " 'able',\n",
       " 'account',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'agent',\n",
       " 'ago',\n",
       " 'air',\n",
       " 'airline',\n",
       " 'airport',\n",
       " 'airways',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'already',\n",
       " 'also',\n",
       " 'always',\n",
       " 'amaze',\n",
       " 'american',\n",
       " 'americanair',\n",
       " 'americanair flight',\n",
       " 'americanair thank',\n",
       " 'americanair thanks',\n",
       " 'amp',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'app',\n",
       " 'appreciate',\n",
       " 'around',\n",
       " 'arrive',\n",
       " 'ask',\n",
       " 'assistance',\n",
       " 'attendant',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'bc',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'big',\n",
       " 'board',\n",
       " 'boarding',\n",
       " 'book',\n",
       " 'book flight',\n",
       " 'booking',\n",
       " 'booking problems',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bring',\n",
       " 'broken',\n",
       " 'business',\n",
       " 'ca',\n",
       " 'ca get',\n",
       " 'call',\n",
       " 'call back',\n",
       " 'cancelled',\n",
       " 'cancelled flight',\n",
       " 'cancelled flight flight',\n",
       " 'cancelled flighted',\n",
       " 'cancelled flighted flight',\n",
       " 'cancelled flightled',\n",
       " 'cancelled flightled flight',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'carry',\n",
       " 'cause',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'change flight',\n",
       " 'charge',\n",
       " 'charlotte',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'chicago',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'clt',\n",
       " 'co',\n",
       " 'come',\n",
       " 'company',\n",
       " 'complaint',\n",
       " 'computer',\n",
       " 'confirm',\n",
       " 'confirmation',\n",
       " 'connect',\n",
       " 'connect flight',\n",
       " 'connection',\n",
       " 'contact',\n",
       " 'cool',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'credit',\n",
       " 'crew',\n",
       " 'customer',\n",
       " 'customer service',\n",
       " 'dallas',\n",
       " 'day',\n",
       " 'dca',\n",
       " 'deal',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delayed flight',\n",
       " 'deliver',\n",
       " 'delta',\n",
       " 'denver',\n",
       " 'departure',\n",
       " 'desk',\n",
       " 'destination',\n",
       " 'destinationdragons',\n",
       " 'dfw',\n",
       " 'different',\n",
       " 'direct',\n",
       " 'disappointed',\n",
       " 'disconnect',\n",
       " 'dm',\n",
       " 'drive',\n",
       " 'due',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'easy',\n",
       " 'else',\n",
       " 'email',\n",
       " 'employee',\n",
       " 'end',\n",
       " 'enough',\n",
       " 'error',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'ewr',\n",
       " 'expect',\n",
       " 'experience',\n",
       " 'extra',\n",
       " 'fail',\n",
       " 'family',\n",
       " 'far',\n",
       " 'fee',\n",
       " 'feel',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'first',\n",
       " 'first class',\n",
       " 'fix',\n",
       " 'fleek',\n",
       " 'fleek http',\n",
       " 'fleek http co',\n",
       " 'fleet',\n",
       " 'fleet fleek',\n",
       " 'fleet fleek http',\n",
       " 'flight',\n",
       " 'flight attendant',\n",
       " 'flight booking',\n",
       " 'flight booking problems',\n",
       " 'flight cancelled',\n",
       " 'flight cancelled flighted',\n",
       " 'flight cancelled flightled',\n",
       " 'flight delayed',\n",
       " 'flight flight',\n",
       " 'flight get',\n",
       " 'flight tomorrow',\n",
       " 'flighted',\n",
       " 'flighted flight',\n",
       " 'flightled',\n",
       " 'flightled flight',\n",
       " 'flightr',\n",
       " 'fll',\n",
       " 'flt',\n",
       " 'fly',\n",
       " 'follow',\n",
       " 'food',\n",
       " 'found',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'frustrate',\n",
       " 'full',\n",
       " 'gate',\n",
       " 'gate agent',\n",
       " 'get',\n",
       " 'get flight',\n",
       " 'get home',\n",
       " 'give',\n",
       " 'go',\n",
       " 'good',\n",
       " 'great',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'gt',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'half',\n",
       " 'handle',\n",
       " 'hang',\n",
       " 'happen',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hear',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'hold',\n",
       " 'hold hour',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'horrible',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hour delay',\n",
       " 'hour hold',\n",
       " 'hour late',\n",
       " 'houston',\n",
       " 'hr',\n",
       " 'http',\n",
       " 'http co',\n",
       " 'hung',\n",
       " 'iad',\n",
       " 'idea',\n",
       " 'im',\n",
       " 'info',\n",
       " 'instead',\n",
       " 'issue',\n",
       " 'jetblue',\n",
       " 'jetblue fleet',\n",
       " 'jetblue fleet fleek',\n",
       " 'jetblue flight',\n",
       " 'jetblue thank',\n",
       " 'jetblue thanks',\n",
       " 'jfk',\n",
       " 'job',\n",
       " 'keep',\n",
       " 'kid',\n",
       " 'know',\n",
       " 'la',\n",
       " 'land',\n",
       " 'last',\n",
       " 'last night',\n",
       " 'late',\n",
       " 'late flight',\n",
       " 'late flightr',\n",
       " 'lax',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'left',\n",
       " 'less',\n",
       " 'let',\n",
       " 'lga',\n",
       " 'lie',\n",
       " 'like',\n",
       " 'line',\n",
       " 'link',\n",
       " 'list',\n",
       " 'little',\n",
       " 'load',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'lose',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'luggage',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'mechanical',\n",
       " 'member',\n",
       " 'message',\n",
       " 'might',\n",
       " 'mile',\n",
       " 'min',\n",
       " 'minute',\n",
       " 'miss',\n",
       " 'miss connection',\n",
       " 'money',\n",
       " 'month',\n",
       " 'morning',\n",
       " 'move',\n",
       " 'much',\n",
       " 'name',\n",
       " 'need',\n",
       " 'need help',\n",
       " 'never',\n",
       " 'never fly',\n",
       " 'new',\n",
       " 'newark',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nothing',\n",
       " 'number',\n",
       " 'nyc',\n",
       " 'offer',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'old',\n",
       " 'one',\n",
       " 'online',\n",
       " 'open',\n",
       " 'option',\n",
       " 'ord',\n",
       " 'paid',\n",
       " 'pas',\n",
       " 'passenger',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'people',\n",
       " 'person',\n",
       " 'phl',\n",
       " 'phone',\n",
       " 'phx',\n",
       " 'pilot',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'plane',\n",
       " 'please',\n",
       " 'please help',\n",
       " 'plus',\n",
       " 'point',\n",
       " 'policy',\n",
       " 'poor',\n",
       " 'possible',\n",
       " 'price',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'provide',\n",
       " 'purchase',\n",
       " 'put',\n",
       " 'question',\n",
       " 'reach',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'rebook',\n",
       " 'rebooked',\n",
       " 'receive',\n",
       " 'refund',\n",
       " 'rep',\n",
       " 'reply',\n",
       " 'request',\n",
       " 'reschedule',\n",
       " 'reservation',\n",
       " 'respond',\n",
       " 'response',\n",
       " 'return',\n",
       " 'ridiculous',\n",
       " 'right',\n",
       " 'room',\n",
       " 'row',\n",
       " 'rt',\n",
       " 'rt jetblue',\n",
       " 'rude',\n",
       " 'run',\n",
       " 'runway',\n",
       " 'san',\n",
       " 'sat',\n",
       " 'say',\n",
       " 'schedule',\n",
       " 'seat',\n",
       " 'second',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'send',\n",
       " 'sent',\n",
       " 'seriously',\n",
       " 'service',\n",
       " 'sfo',\n",
       " 'share',\n",
       " 'show',\n",
       " 'since',\n",
       " 'sit',\n",
       " 'site',\n",
       " 'sleep',\n",
       " 'snow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'southwest',\n",
       " 'southwestair',\n",
       " 'southwestair flight',\n",
       " 'southwestair thank',\n",
       " 'southwestair thanks',\n",
       " 'speak',\n",
       " 'staff',\n",
       " 'start',\n",
       " 'status',\n",
       " 'stay',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'strand',\n",
       " 'stuck',\n",
       " 'suck',\n",
       " 'suppose',\n",
       " 'sure',\n",
       " 'swa',\n",
       " 'switch',\n",
       " 'system',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'tarmac',\n",
       " 'team',\n",
       " 'tell',\n",
       " 'terminal',\n",
       " 'terrible',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'thru',\n",
       " 'thx',\n",
       " 'ticket',\n",
       " 'time',\n",
       " 'today',\n",
       " 'together',\n",
       " 'told',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'travel',\n",
       " 'treat',\n",
       " 'trip',\n",
       " 'try',\n",
       " 'try get',\n",
       " 'tweet',\n",
       " 'twice',\n",
       " 'twitter',\n",
       " 'two',\n",
       " 'two hour',\n",
       " 'ua',\n",
       " 'unacceptable',\n",
       " 'understand',\n",
       " 'united',\n",
       " 'united flight',\n",
       " 'united thank',\n",
       " 'united thanks',\n",
       " 'united yes',\n",
       " 'update',\n",
       " 'upgrade',\n",
       " 'ur',\n",
       " 'us',\n",
       " 'usairways',\n",
       " 'usairways americanair',\n",
       " 'usairways flight',\n",
       " 'usairways hold',\n",
       " 'usairways thanks',\n",
       " 'use',\n",
       " 'vacation',\n",
       " 'vegas',\n",
       " 'via',\n",
       " 'virginamerica',\n",
       " 'voucher',\n",
       " 'wait',\n",
       " 'wait time',\n",
       " 'want',\n",
       " 'watch',\n",
       " 'way',\n",
       " 'weather',\n",
       " 'website',\n",
       " 'week',\n",
       " 'well',\n",
       " 'wife',\n",
       " 'wifi',\n",
       " 'without',\n",
       " 'wo',\n",
       " 'work',\n",
       " 'worst',\n",
       " 'would',\n",
       " 'wrong',\n",
       " 'year',\n",
       " 'yes',\n",
       " 'yesterday',\n",
       " 'yet']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GEtting list of feature name obtained from count vectorizer\n",
    "count_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '11',\n",
       " '15',\n",
       " '1st',\n",
       " '20',\n",
       " '30',\n",
       " '40',\n",
       " '45',\n",
       " '50',\n",
       " 'aa',\n",
       " 'able',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'agent',\n",
       " 'ago',\n",
       " 'air',\n",
       " 'airline',\n",
       " 'airport',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'already',\n",
       " 'also',\n",
       " 'always',\n",
       " 'amaze',\n",
       " 'american',\n",
       " 'americanair',\n",
       " 'americanair flight',\n",
       " 'americanair thanks',\n",
       " 'amp',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'app',\n",
       " 'appreciate',\n",
       " 'arrive',\n",
       " 'ask',\n",
       " 'attendant',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'best',\n",
       " 'big',\n",
       " 'board',\n",
       " 'boarding',\n",
       " 'book',\n",
       " 'book flight',\n",
       " 'booking',\n",
       " 'booking problems',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'business',\n",
       " 'ca',\n",
       " 'ca get',\n",
       " 'call',\n",
       " 'call back',\n",
       " 'cancelled',\n",
       " 'cancelled flight',\n",
       " 'cancelled flighted',\n",
       " 'cancelled flightled',\n",
       " 'cancelled flightled flight',\n",
       " 'card',\n",
       " 'care',\n",
       " 'cause',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'change flight',\n",
       " 'charge',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'chicago',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'clt',\n",
       " 'co',\n",
       " 'come',\n",
       " 'company',\n",
       " 'connect',\n",
       " 'connect flight',\n",
       " 'connection',\n",
       " 'contact',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'credit',\n",
       " 'crew',\n",
       " 'customer',\n",
       " 'customer service',\n",
       " 'dallas',\n",
       " 'day',\n",
       " 'dca',\n",
       " 'deal',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delta',\n",
       " 'denver',\n",
       " 'departure',\n",
       " 'desk',\n",
       " 'destination',\n",
       " 'destinationdragons',\n",
       " 'dfw',\n",
       " 'different',\n",
       " 'direct',\n",
       " 'disappointed',\n",
       " 'dm',\n",
       " 'due',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'email',\n",
       " 'employee',\n",
       " 'end',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'ewr',\n",
       " 'expect',\n",
       " 'experience',\n",
       " 'extra',\n",
       " 'fail',\n",
       " 'family',\n",
       " 'far',\n",
       " 'fee',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'first',\n",
       " 'fix',\n",
       " 'fleek',\n",
       " 'fleek http',\n",
       " 'fleek http co',\n",
       " 'fleet',\n",
       " 'fleet fleek',\n",
       " 'fleet fleek http',\n",
       " 'flight',\n",
       " 'flight attendant',\n",
       " 'flight booking',\n",
       " 'flight booking problems',\n",
       " 'flight cancelled',\n",
       " 'flight cancelled flightled',\n",
       " 'flight delayed',\n",
       " 'flighted',\n",
       " 'flightled',\n",
       " 'flightled flight',\n",
       " 'flightr',\n",
       " 'flt',\n",
       " 'fly',\n",
       " 'follow',\n",
       " 'food',\n",
       " 'found',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'frustrate',\n",
       " 'full',\n",
       " 'gate',\n",
       " 'gate agent',\n",
       " 'get',\n",
       " 'get home',\n",
       " 'give',\n",
       " 'go',\n",
       " 'good',\n",
       " 'great',\n",
       " 'ground',\n",
       " 'gt',\n",
       " 'guy',\n",
       " 'hang',\n",
       " 'happen',\n",
       " 'happy',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'hold',\n",
       " 'hold hour',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'horrible',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hour late',\n",
       " 'hr',\n",
       " 'http',\n",
       " 'http co',\n",
       " 'hung',\n",
       " 'info',\n",
       " 'instead',\n",
       " 'issue',\n",
       " 'jetblue',\n",
       " 'jetblue fleet',\n",
       " 'jetblue fleet fleek',\n",
       " 'jetblue flight',\n",
       " 'jetblue thanks',\n",
       " 'jfk',\n",
       " 'job',\n",
       " 'keep',\n",
       " 'kid',\n",
       " 'know',\n",
       " 'land',\n",
       " 'last',\n",
       " 'late',\n",
       " 'late flight',\n",
       " 'late flightr',\n",
       " 'lax',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'left',\n",
       " 'let',\n",
       " 'like',\n",
       " 'line',\n",
       " 'link',\n",
       " 'little',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lose',\n",
       " 'love',\n",
       " 'luggage',\n",
       " 'make',\n",
       " 'many',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'member',\n",
       " 'message',\n",
       " 'might',\n",
       " 'mile',\n",
       " 'min',\n",
       " 'minute',\n",
       " 'miss',\n",
       " 'miss connection',\n",
       " 'money',\n",
       " 'month',\n",
       " 'morning',\n",
       " 'move',\n",
       " 'much',\n",
       " 'name',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nothing',\n",
       " 'number',\n",
       " 'nyc',\n",
       " 'offer',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'old',\n",
       " 'one',\n",
       " 'online',\n",
       " 'open',\n",
       " 'option',\n",
       " 'ord',\n",
       " 'paid',\n",
       " 'pas',\n",
       " 'passenger',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'people',\n",
       " 'person',\n",
       " 'phl',\n",
       " 'phone',\n",
       " 'phx',\n",
       " 'pilot',\n",
       " 'plan',\n",
       " 'plane',\n",
       " 'please',\n",
       " 'please help',\n",
       " 'point',\n",
       " 'policy',\n",
       " 'poor',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'provide',\n",
       " 'put',\n",
       " 'question',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'rebook',\n",
       " 'rebooked',\n",
       " 'receive',\n",
       " 'refund',\n",
       " 'rep',\n",
       " 'reply',\n",
       " 'reschedule',\n",
       " 'reservation',\n",
       " 'respond',\n",
       " 'response',\n",
       " 'return',\n",
       " 'ridiculous',\n",
       " 'right',\n",
       " 'rt',\n",
       " 'rude',\n",
       " 'run',\n",
       " 'san',\n",
       " 'say',\n",
       " 'schedule',\n",
       " 'seat',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'send',\n",
       " 'sent',\n",
       " 'seriously',\n",
       " 'service',\n",
       " 'sfo',\n",
       " 'show',\n",
       " 'since',\n",
       " 'sit',\n",
       " 'site',\n",
       " 'snow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sorry',\n",
       " 'southwest',\n",
       " 'southwestair',\n",
       " 'southwestair flight',\n",
       " 'southwestair thanks',\n",
       " 'speak',\n",
       " 'staff',\n",
       " 'start',\n",
       " 'status',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'strand',\n",
       " 'stuck',\n",
       " 'suck',\n",
       " 'suppose',\n",
       " 'sure',\n",
       " 'system',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'tarmac',\n",
       " 'team',\n",
       " 'tell',\n",
       " 'terrible',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'though',\n",
       " 'thx',\n",
       " 'ticket',\n",
       " 'time',\n",
       " 'today',\n",
       " 'told',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'travel',\n",
       " 'trip',\n",
       " 'try',\n",
       " 'try get',\n",
       " 'tweet',\n",
       " 'twitter',\n",
       " 'two',\n",
       " 'unacceptable',\n",
       " 'understand',\n",
       " 'united',\n",
       " 'united flight',\n",
       " 'united thank',\n",
       " 'united thanks',\n",
       " 'update',\n",
       " 'upgrade',\n",
       " 'ur',\n",
       " 'us',\n",
       " 'usairways',\n",
       " 'usairways americanair',\n",
       " 'usairways flight',\n",
       " 'usairways hold',\n",
       " 'usairways thanks',\n",
       " 'use',\n",
       " 'via',\n",
       " 'virginamerica',\n",
       " 'voucher',\n",
       " 'wait',\n",
       " 'want',\n",
       " 'way',\n",
       " 'weather',\n",
       " 'website',\n",
       " 'week',\n",
       " 'well',\n",
       " 'wife',\n",
       " 'wifi',\n",
       " 'without',\n",
       " 'wo',\n",
       " 'work',\n",
       " 'would',\n",
       " 'year',\n",
       " 'yes',\n",
       " 'yesterday',\n",
       " 'yet']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GEtting list of feature name obtained from TFIDF vectorizer\n",
    "tfidf_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRIDSEARCHING ON DIFFERENT ALGO AND CHECKING WHICH GIVE A BETTER ACCURACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch for SVC\n",
    "clf_SVC = SVC()\n",
    "grid_SVC = {'C':[10,1e2,5e2,1e3,5e3],'gamma':[1e-2,1e-3,1e-4,5e-3]}\n",
    "gridsearch_SVC = GridSearchCV(clf_SVC,grid_SVC,cv=KFold(n_splits=3,shuffle=True,random_state=0))\n",
    "gridsearch_SVC.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_SVC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = SVC(C=10,gamma=0.01)\n",
    "clf_SVC.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BY USING TFIDF VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = SVC()\n",
    "grid_SVC = {'C':[10,1e2,5e2,1e3,5e3],'gamma':[1e-2,1e-3,1e-4,5e-3]}\n",
    "gridsearch_SVC = GridSearchCV(clf_SVC,grid_SVC,cv=KFold(n_splits=3,shuffle=True,random_state=0))\n",
    "gridsearch_SVC.fit(xtrain2,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_SVC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-fb6803af3d16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mypred_SVC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_SVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf_SVC' is not defined"
     ]
    }
   ],
   "source": [
    "ypred_SVC = clf_SVC.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"ypred_svc.csv\",ypred_SVC,fmt='%s',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.KNN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=0, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [11, 13, 15, 17]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_KNN = KNeighborsClassifier()\n",
    "grid_KNN = {'n_neighbors':[11,13,15,17]}\n",
    "gridsearch_KNN = GridSearchCV(clf_KNN,grid_KNN,cv=KFold(n_splits=3,shuffle=True,random_state=0))\n",
    "gridsearch_KNN.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=11, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_KNN.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58205828779599267"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_KNN.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=0, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [5, 10, 15, 20, 25, 30], 'max_depth': [5, 10, 15, 20, 25, 30, 35]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RFC = RandomForestClassifier(criterion=\"entropy\")\n",
    "grid_RFC = {\"n_estimators\":[5,10,15,20,25,30],\"max_depth\":[5,10,15,20,25,30,35]}\n",
    "gridsearch_RFC=GridSearchCV(clf_RFC,grid_RFC,cv=KFold(n_splits=3,shuffle=True,random_state=0))\n",
    "gridsearch_RFC.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=35, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_RFC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72222222222222221"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_RFC.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
